"use strict";(globalThis.webpackChunkphysical_ai_robotics_textbook=globalThis.webpackChunkphysical_ai_robotics_textbook||[]).push([[6161],{4055:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>c,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"vla-humanoids/week-11-vla","title":"Vision-Language-Action (VLA)","description":"This week, we will cover the basics of Vision-Language-Action (VLA).","source":"@site/docs/05-vla-humanoids/week-11-vla.md","sourceDirName":"05-vla-humanoids","slug":"/vla-humanoids/week-11-vla","permalink":"/ai-driven-hackathon/docs/vla-humanoids/week-11-vla","draft":false,"unlisted":false,"editUrl":"https://github.com/Muhammadtalha678/ai-driven-hackathon/tree/main/frontend/docs/05-vla-humanoids/week-11-vla.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"NVIDIA Isaac Sim","permalink":"/ai-driven-hackathon/docs/isaac-sim/week-8-setup"},"next":{"title":"Cloud-Native Setup","permalink":"/ai-driven-hackathon/docs/setup/cloud-native"}}');var o=i(4848),a=i(8453);const s={sidebar_position:1},c="Vision-Language-Action (VLA)",r={},l=[{value:"Voice-to-Action using OpenAI Whisper",id:"voice-to-action-using-openai-whisper",level:2},{value:"Cognitive Planning using LLMs",id:"cognitive-planning-using-llms",level:2}];function h(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"vision-language-action-vla",children:"Vision-Language-Action (VLA)"})}),"\n",(0,o.jsx)(n.p,{children:"This week, we will cover the basics of Vision-Language-Action (VLA)."}),"\n",(0,o.jsx)(n.h2,{id:"voice-to-action-using-openai-whisper",children:"Voice-to-Action using OpenAI Whisper"}),"\n",(0,o.jsx)(n.p,{children:"OpenAI's Whisper is a powerful speech-to-text model that can be used to create a voice-to-action system for your robot. You can use Whisper to transcribe voice commands, and then use a large language model (LLM) to translate those commands into a sequence of actions for your robot."}),"\n",(0,o.jsx)(n.h2,{id:"cognitive-planning-using-llms",children:"Cognitive Planning using LLMs"}),"\n",(0,o.jsx)(n.p,{children:'Large language models (LLMs) can be used for cognitive planning. This means that you can use an LLM to translate a high-level command, such as "Clean the room", into a sequence of low-level actions that your robot can execute. For example, the LLM might generate a plan like this:'}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Find the trash can."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Pick up any trash on the floor."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Put the trash in the trash can."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Find the vacuum cleaner."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Vacuum the floor."}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>c});var t=i(6540);const o={},a=t.createContext(o);function s(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);